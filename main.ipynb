{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"<s>[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an integral part of a word-searching algorithm. \\\n",
    "In essence, you are a linguistic expert being tasked with \\\n",
    "modifying and combining text in creative but coherent new ways. \\\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_llama_prompt(prompt, sys_prompt=None):\n",
    "    sys_prompt = sys_prompt or SYSTEM_PROMPT\n",
    "    prompt_template =  B_INST + B_SYS + sys_prompt + E_SYS + prompt + E_INST\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "\n",
    "default_params = {\n",
    "    GenParams.DECODING_METHOD: 'sample',\n",
    "    GenParams.MIN_NEW_TOKENS: 10,\n",
    "    GenParams.MAX_NEW_TOKENS: 25,\n",
    "    GenParams.TEMPERATURE: 0.25,\n",
    "    GenParams.RANDOM_SEED: 42,\n",
    "    GenParams.REPETITION_PENALTY: 1.05,\n",
    "}\n",
    "\n",
    "supported_models = [\n",
    "    'bigcode/starcoder', \n",
    "    'bigscience/mt0-xxl', \n",
    "    'codellama/codellama-34b-instruct-hf', \n",
    "    'google/flan-t5-xl', \n",
    "    'google/flan-t5-xxl', \n",
    "    'google/flan-ul2', \n",
    "    'ibm-mistralai/mixtral-8x7b-instruct-v01-q', \n",
    "    'ibm/granite-13b-chat-v1', \n",
    "    'ibm/granite-13b-chat-v2', \n",
    "    'ibm/granite-13b-instruct-v1', \n",
    "    'ibm/granite-13b-instruct-v2', \n",
    "    'ibm/granite-20b-multilingual', \n",
    "    'meta-llama/llama-2-13b-chat', \n",
    "    'meta-llama/llama-2-70b-chat'\n",
    "]\n",
    "\n",
    "def generate_text(prompt, model='meta-llama/llama-2-13b-chat', new_params={}, sys_prompt=None):\n",
    "    if not prompt.startswith(B_INST) and prompt.endswith(E_INST):\n",
    "        prompt = get_llama_prompt(prompt, sys_prompt)\n",
    "    \n",
    "    params = dict(default_params)\n",
    "    params.update(new_params)\n",
    "\n",
    "    llm = Model(\n",
    "        model_id=model,\n",
    "        params=params,\n",
    "        credentials={\n",
    "            'apikey' : os.environ['WATSONX_API_KEY'], \n",
    "            'url' : os.environ['WATSONX_URL']\n",
    "        },\n",
    "        project_id=os.environ['WATSONX_PROJECT_ID']\n",
    "    )\n",
    "    return llm.generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate_text('why is the sky blue?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def trim_incomplete_response(\n",
    "        response, \n",
    "        delimiters=('.', '!', '?'), \n",
    "        comma_is_delimiter=False, \n",
    "        delim_follows_text=0,\n",
    "        include_quotes=True,\n",
    "        cutoff_str='...', \n",
    "        strip_ws=True,\n",
    "        ):\n",
    "    trimmed = str(response)\n",
    "    if not response.endswith(delimiters):\n",
    "        assert delim_follows_text < len(response), f'delim_follows_text ({delim_follows_text}) must be '\n",
    "        i = len(response)\n",
    "        while i > 0:\n",
    "            i -= 1\n",
    "            if response[i] in delimiters:\n",
    "                if delim_follows_text > 0:\n",
    "                    if not all(char in string.ascii_letters for char in response[i-delim_follows_text:i]):\n",
    "                        continue\n",
    "                trimmed = response[:i+1]\n",
    "                break\n",
    "            elif response[i] == ',' and comma_is_delimiter:\n",
    "                trimmed = response[:i] + cutoff_str\n",
    "                break\n",
    "        if include_quotes:\n",
    "            if response[i+1] == \"'\":\n",
    "                trimmed += \"'\"\n",
    "            elif response[i+1] == \"\\\"\":\n",
    "                trimmed += \"\\\"\"\n",
    "        if strip_ws:\n",
    "            trimmed = trimmed.strip()\n",
    "    return trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = \\\n",
    "# '''\n",
    "# Take the following text and change some of the words significantly:\n",
    "\n",
    "# 1. \"A black horse on a white background.\"\n",
    "#     - \"The silhouette of a horse over a white background.\" \n",
    "#     - \"A dark colored horse on a light colored background.\"\n",
    "\n",
    "# 2. \"Two businessmen shaking hands on a sidewalk.\"\n",
    "#     - \"One businessman shaking another businessman's hand on the street.\" \n",
    "#     - \"Two businessmen greeting each other on the sidewalk.\"\n",
    "\n",
    "# 3. \"The sky appears blue because of a phenomenon called Rayleigh scattering.\"\n",
    "#     - \"The sky looks blue because of a scientific principle called Rayleigh scattering.\"\n",
    "#     - \"The sky's blue color is due to a natural process known as Rayleigh scattering.\"\n",
    "\n",
    "# 4. \"The\n",
    "# '''\n",
    "# result = trim_incomplete_response(test, delim_follows_text=False)\n",
    "# print(f'\\n\\n{result}')\n",
    "# result = trim_incomplete_response(test, delim_follows_text=2)\n",
    "# print(f'\\n\\n{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_params = {\n",
    "    GenParams.DECODING_METHOD: 'sample',\n",
    "    GenParams.MIN_NEW_TOKENS: 10,\n",
    "    GenParams.MAX_NEW_TOKENS: 25,\n",
    "    GenParams.TEMPERATURE: 0.25,\n",
    "    # GenParams.RANDOM_SEED: 42,\n",
    "    GenParams.REPETITION_PENALTY: 1.05,\n",
    "}\n",
    "\n",
    "question = 'why is the sky blue?'\n",
    "\n",
    "\n",
    "def ask(question, new_params={}, verbose=False):\n",
    "    params = dict(question_params)\n",
    "    params.update(new_params)\n",
    "    if verbose: print(question)\n",
    "\n",
    "    response = generate_text(question, new_params=params)\n",
    "    if verbose: print(response)\n",
    "\n",
    "    trimmed_response = trim_incomplete_response(\n",
    "        response, \n",
    "        comma_is_delimiter=True, \n",
    "        cutoff_str='.', \n",
    "        delim_follows_text=2\n",
    "        )\n",
    "    if verbose: print(trimmed_response)\n",
    "    return trimmed_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRONG = ' significantly'\n",
    "MEDIUM = ''\n",
    "WEAK = ' a little bit'\n",
    "strengths = [WEAK, MEDIUM, STRONG]\n",
    "\n",
    "\n",
    "def mutate_prompt(orig_text, strength=STRONG):\n",
    "    assert strength in strengths\n",
    "    return \\\n",
    "f'''\n",
    "Take the following text and change some of the words{strength}:\n",
    "\n",
    "1. \"A black horse on a white background\"\n",
    "    - \"The silhouette of a horse over a white background\" \n",
    "    - \"A dark colored horse on a light colored background\"\n",
    "\n",
    "2. \"Two businessmen shaking hands on a sidewalk\"\n",
    "    - \"One businessman shaking another businessman's hand on the street\" \n",
    "    - \"Two businessmen greeting each other on the sidewalk\"\n",
    "\n",
    "3. \"{orig_text}\"'''\n",
    "\n",
    "mutate_params = {\n",
    "    GenParams.DECODING_METHOD: 'sample',\n",
    "    GenParams.MIN_NEW_TOKENS: 20,\n",
    "    GenParams.MAX_NEW_TOKENS: 50,\n",
    "    GenParams.TEMPERATURE: 0.60,\n",
    "    # GenParams.RANDOM_SEED: 42,\n",
    "    GenParams.REPETITION_PENALTY: 1.0,\n",
    "}\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_mutation_strings(mutated_text):\n",
    "    return re.findall(r\"(\\w+[\\w| |']*.?)\", mutated_text)\n",
    "\n",
    "\n",
    "def mutate(original_text, new_params={}, verbose=False, trim=2, extract=True):\n",
    "    params = dict(mutate_params)\n",
    "    params.update(new_params)\n",
    "    mutation_prompt = mutate_prompt(original_text)\n",
    "    if verbose: print(mutation_prompt, end='')\n",
    "    mutated_response = generate_text(mutation_prompt, new_params=params)\n",
    "    if verbose: print(mutated_response)\n",
    "    if trim > 0: \n",
    "        mutated_response = trim_incomplete_response(mutated_response, delim_follows_text=trim, strip_ws=False)\n",
    "    if verbose: print('trimmed:', mutated_response)\n",
    "    return extract_mutation_strings(mutated_response) if extract else mutated_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why is they sky blue?\n",
      "The sky appears blue because of a phenomenon called Rayleigh scattering.\n",
      "The sky appears blue because of a process called Rayleigh scattering.\n",
      "The sky has a blue color due to a scientific concept called Rayleigh scattering.\n"
     ]
    }
   ],
   "source": [
    "question = 'why is they sky blue?'\n",
    "print(question)\n",
    "\n",
    "answer = ask(question)\n",
    "print(answer)\n",
    "\n",
    "rephrasings = mutate(answer)\n",
    "for rephrasing in rephrasings:\n",
    "    print(rephrasing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why does the sea sometimes glow around me when I wade through it at night?\n",
      "The sea can sometimes glow at night due to a phenomenon called bioluminescence. This occurs when microorganisms such as plankton, algae, or bacteria in the water produce light as a result of chemical reactions.\n",
      "The ocean can sometimes emit a glowing light at night due to the presence of microorganisms that produce light as a result of chemical reactions.\n",
      "The waves can sometimes shimmer in the dark due to the presence of tiny organisms that emit light.\n"
     ]
    }
   ],
   "source": [
    "question = 'why does the sea sometimes glow around me when I wade through it at night?'\n",
    "print(question)\n",
    "\n",
    "answer = ask(question, new_params={\n",
    "    GenParams.MIN_NEW_TOKENS: 10,\n",
    "    GenParams.MAX_NEW_TOKENS: 60,\n",
    "    })\n",
    "print(answer)\n",
    "\n",
    "rephrasings = mutate(answer, new_params={\n",
    "    GenParams.MIN_NEW_TOKENS: 10,\n",
    "    GenParams.MAX_NEW_TOKENS: 100,\n",
    "    })\n",
    "for rephrasing in rephrasings:\n",
    "    print(rephrasing)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
